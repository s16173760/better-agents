<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- cursor Session 982290bb-f71d-4d43-b118-37d534f42b3c (2025-12-04 16:15Z) -->

# Check MCP for AI SDK agent writing (2025-12-04 16:15Z)

_**User (2025-12-04 14:48Z)**_

check the mcp, how does it tell you to write ai sdk agent

---

_**Agent (model claude-4.5-opus-high-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user wants me to check the MCP (Model Context Protocol) documentation to see how it tells me to write an AI SDK agent. Let me first list the available documentation sources from the MCP server.</details></think>

---

<tool-use data-tool-type="mcp" data-tool-name="mcp_vercel_list_doc_sources">
<details>
          <summary>Tool use: **mcp_vercel_list_doc_sources**</summary>
      
*Called tool*: vercel - list_doc_sources: List all available documentation sources.

This is the first tool you should call in the documentation workflow.
It provides URLs to llms.txt files or local file paths that the user has made available.

Returns:
    A string containing a formatted list of documentation sources with their URLs or file paths


*Parameters*:
  * 

*Result*:
Vercel
URL: https://ai-sdk.dev/docs/introduction


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Now let me fetch the Vercel AI SDK documentation to understand its structure and find information about writing agents.</details></think>

---

<tool-use data-tool-type="mcp" data-tool-name="mcp_vercel_fetch_docs">
<details>
          <summary>Tool use: **mcp_vercel_fetch_docs**</summary>
      
*Called tool*: vercel - fetch_docs: Fetch and parse documentation from a given URL or local file.

Use this tool after list_doc_sources to:
1. First fetch the llms.txt file from a documentation source
2. Analyze the URLs listed in the llms.txt file
3. Then fetch specific documentation pages relevant to the user's question

Args:
    url: The URL to fetch documentation from.

Returns:
    The fetched documentation content converted to markdown, or an error message
    if the request fails or the URL is not from an allowed domain.

*Parameters*:
  * url: https://ai-sdk.dev/docs/introduction

*Result*:
AI SDK by Vercel

* [Docs](/docs)
* [Cookbook](/cookbook)
* [Providers](/providers)
* [Tools RegistryTools](/tools-registry)
* [Playground](/playground)
* [AI ElementsAI Elements](/elements)
* [AI GatewayGateway](https://vercel.com/ai-gateway)

AI SDK 6 is in Beta.

[Learn more](/docs/introduction/announcing-ai-sdk-6-beta)

Menu

v5 (Latest)

AI SDK 5.x

[AI SDK by Vercel](/docs/introduction)

[AI SDK 6 Beta](/docs/announcing-ai-sdk-6-beta)

[Foundations](/docs/foundations)

[Overview](/docs/foundations/overview)

[Providers and Models](/docs/foundations/providers-and-models)

[Prompts](/docs/foundations/prompts)

[Tools](/docs/foundations/tools)

[Streaming](/docs/foundations/streaming)

[Getting Started](/docs/getting-started)

[Navigating the Library](/docs/getting-started/navigating-the-library)

[Next.js App Router](/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](/docs/getting-started/nextjs-pages-router)

[Svelte](/docs/getting-started/svelte)

[Vue.js (Nuxt)](/docs/getting-started/nuxt)

[Node.js](/docs/getting-started/nodejs)

[Expo](/docs/getting-started/expo)

[Agents](/docs/agents)

[Agents](/docs/agents/overview)

[Building Agents](/docs/agents/building-agents)

[Workflow Patterns](/docs/agents/workflows)

[Loop Control](/docs/agents/loop-control)

[AI SDK Core](/docs/ai-sdk-core)

[Overview](/docs/ai-sdk-core/overview)

[Generating Text](/docs/ai-sdk-core/generating-text)

[Generating Structured Data](/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](/docs/ai-sdk-core/tools-and-tool-calling)

[Model Context Protocol (MCP)](/docs/ai-sdk-core/mcp-tools)

[Prompt Engineering](/docs/ai-sdk-core/prompt-engineering)

[Settings](/docs/ai-sdk-core/settings)

[Embeddings](/docs/ai-sdk-core/embeddings)

[Image Generation](/docs/ai-sdk-core/image-generation)

[Transcription](/docs/ai-sdk-core/transcription)

[Speech](/docs/ai-sdk-core/speech)

[Language Model Middleware](/docs/ai-sdk-core/middleware)

[Provider & Model Management](/docs/ai-sdk-core/provider-management)

[Error Handling](/docs/ai-sdk-core/error-handling)

[Testing](/docs/ai-sdk-core/testing)

[Telemetry](/docs/ai-sdk-core/telemetry)

[AI SDK UI](/docs/ai-sdk-ui)

[Overview](/docs/ai-sdk-ui/overview)

[Chatbot](/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Resume Streams](/docs/ai-sdk-ui/chatbot-resume-streams)

[Chatbot Tool Usage](/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](/docs/ai-sdk-ui/completion)

[Object Generation](/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](/docs/ai-sdk-ui/streaming-data)

[Error Handling](/docs/ai-sdk-ui/error-handling)

[Transport](/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](/docs/ai-sdk-rsc)

[Advanced](/docs/advanced)

[Reference](/docs/reference)

[AI SDK Core](/docs/reference/ai-sdk-core)

[AI SDK UI](/docs/reference/ai-sdk-ui)

[AI SDK RSC](/docs/reference/ai-sdk-rsc)

[Stream Helpers](/docs/reference/stream-helpers)

[AI SDK Errors](/docs/reference/ai-sdk-errors)

[Migration Guides](/docs/migration-guides)

[Troubleshooting](/docs/troubleshooting)

AI SDK by Vercel

Copy markdown

[AI SDK](#ai-sdk)
=================

The AI SDK is the TypeScript toolkit designed to help developers build AI-powered applications and agents with React, Next.js, Vue, Svelte, Node.js, and more.

[Why use the AI SDK?](#why-use-the-ai-sdk)
------------------------------------------

Integrating large language models (LLMs) into applications is complicated and heavily dependent on the specific model provider you use.

The AI SDK standardizes integrating artificial intelligence (AI) models across [supported providers](/docs/foundations/providers-and-models). This enables developers to focus on building great AI applications, not waste time on technical details.

For example, here’s how you can generate text with various models using the AI SDK:

Gateway

OpenAI

Anthropic

Google

Custom

import { generateText } from "ai"

const { text } = await generateText({

model: "google/gemini-3-pro-preview",

prompt: "What is love?"

})

Love is a universal emotion that is characterized by feelings of affection, attachment, and warmth towards someone or something. It is a complex and multifaceted experience that can take many different forms, including romantic love, familial love, platonic love, and self-love.

The AI SDK has two main libraries:

* **[AI SDK Core](/docs/ai-sdk-core):** A unified API for generating text, structured objects, tool calls, and building agents with LLMs.
* **[AI SDK UI](/docs/ai-sdk-ui):** A set of framework-agnostic hooks for quickly building chat and generative user interface.

[Model Providers](#model-providers)
-----------------------------------

The AI SDK supports [multiple model providers](/providers).

[Vercel AI Gateway

Image InputImage GenerationObject GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/ai-gateway)[OpenAI

Image InputImage GenerationObject GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/openai)[Anthropic

Image InputObject GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/anthropic)[Google Generative AI

![Google Generative AI logo](/_next/image?url=%2Ficons%2Fgoogle.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)

Image InputObject GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/google-generative-ai)[xAI Grok

Image InputImage GenerationObject GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/xai)[Azure

![Azure logo](/_next/image?url=%2Ficons%2Fazure.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)

Image InputObject GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/azure)[Amazon Bedrock

Image InputImage GenerationObject GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/amazon-bedrock)[Groq

Image InputObject GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/groq)[Fal AI

Image Generation](/providers/ai-sdk-providers/fal)[DeepInfra

Image InputObject GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/deepinfra)[Google Vertex AI

![Google Vertex AI logo](/_next/image?url=%2Ficons%2Fgoogle.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)

Image InputImage GenerationObject GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/google-vertex)[Mistral

![Mistral logo](/_next/image?url=%2Ficons%2Fmistral.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)

Image InputObject GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/mistral)[Together.ai

Object GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/togetherai)[Cohere

![Cohere logo](/_next/image?url=%2Ficons%2Fcohere.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)

Tool UsageTool Streaming](/providers/ai-sdk-providers/cohere)[Fireworks

![Fireworks logo](/_next/image?url=%2Ficons%2Ffireworks.png&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)

Image GenerationObject GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/fireworks)[DeepSeek

![DeepSeek logo](/_next/image?url=%2Ficons%2Fdeepseek.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)

Object GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/deepseek)[Cerebras

Object GenerationTool UsageTool Streaming](/providers/ai-sdk-providers/cerebras)[Perplexity

![Perplexity logo](/_next/image?url=%2Ficons%2Fperplexity.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)](/providers/ai-sdk-providers/perplexity)[Luma AI

![Luma AI logo](/_next/image?url=%2Ficons%2Fluma.png&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)

Image Generation](/providers/ai-sdk-providers/luma)[Baseten

![Baseten logo](/_next/image?url=%2Ficons%2Fbaseten.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)

Object GenerationTool Usage](/providers/ai-sdk-providers/baseten)

[Templates](#templates)
-----------------------

We've built some [templates](https://vercel.com/templates?type=ai) that include AI SDK integrations for different use cases, providers, and frameworks. You can use these templates to get started with your AI-powered application.

### [Starter Kits](#starter-kits)

[Chatbot Starter Template

Uses the AI SDK and Next.js. Features persistence, multi-modal chat, and more.](https://vercel.com/templates/next.js/nextjs-ai-chatbot)[Internal Knowledge Base (RAG)

Uses AI SDK Language Model Middleware for RAG and enforcing guardrails.](https://vercel.com/templates/next.js/ai-sdk-internal-knowledge-base)[Multi-Modal Chat

Uses Next.js and AI SDK useChat hook for multi-modal message chat interface.](https://vercel.com/templates/next.js/multi-modal-chatbot)[Semantic Image Search

An AI semantic image search app template built with Next.js, AI SDK, and Postgres.](https://vercel.com/templates/next.js/semantic-image-search)[Natural Language PostgreSQL

Query PostgreSQL using natural language with AI SDK and GPT-4o.](https://vercel.com/templates/next.js/natural-language-postgres)

### [Feature Exploration](#feature-exploration)

[Feature Flags Example

AI SDK with Next.js, Feature Flags, and Edge Config for dynamic model switching.](https://vercel.com/templates/next.js/ai-sdk-feature-flags-edge-config)[Chatbot with Telemetry

AI SDK chatbot with OpenTelemetry support.](https://vercel.com/templates/next.js/ai-chatbot-telemetry)[Structured Object Streaming

Uses AI SDK useObject hook to stream structured object generation.](https://vercel.com/templates/next.js/use-object)[Multi-Step Tools

Uses AI SDK streamText function to handle multiple tool steps automatically.](https://vercel.com/templates/next.js/ai-sdk-roundtrips)

### [Frameworks](#frameworks)

[Next.js OpenAI Starter

Uses OpenAI GPT-4, AI SDK, and Next.js.](https://github.com/vercel/ai/tree/main/examples/next-openai)[Nuxt OpenAI Starter

Uses OpenAI GPT-4, AI SDK, and Nuxt.js.](https://github.com/vercel/ai/tree/main/examples/nuxt-openai)[SvelteKit OpenAI Starter

Uses OpenAI GPT-4, AI SDK, and SvelteKit.](https://github.com/vercel/ai/tree/main/examples/sveltekit-openai)[Solid OpenAI Starter

Uses OpenAI GPT-4, AI SDK, and Solid.](https://github.com/vercel/ai/tree/main/examples/solidstart-openai)

### [Generative UI](#generative-ui)

[Gemini Chatbot

Uses Google Gemini, AI SDK, and Next.js.](https://vercel.com/templates/next.js/gemini-ai-chatbot)[Generative UI with RSC (experimental)

Uses Next.js, AI SDK, and streamUI to create generative UIs with React Server Components.](https://vercel.com/templates/next.js/rsc-genui)

### [Security](#security)

[Bot Protection

Uses Kasada, OpenAI GPT-4, AI SDK, and Next.js.](https://vercel.com/templates/next.js/advanced-ai-bot-protection)[Rate Limiting

Uses Vercel KV, OpenAI GPT-4, AI SDK, and Next.js.](https://github.com/vercel/ai/tree/main/examples/next-openai-upstash-rate-limits)

[Join our Community](#join-our-community)
-----------------------------------------

If you have questions about anything related to the AI SDK, you're always welcome to ask our community on [the Vercel Community](https://community.vercel.com/c/ai-sdk/62).

[`llms.txt` (for Cursor, Windsurf, Copilot, Claude etc.)](#llmstxt-for-cursor-windsurf-copilot-claude-etc)
----------------------------------------------------------------------------------------------------------

You can access the entire AI SDK documentation in Markdown format at [ai-sdk.dev/llms.txt](/llms.txt). This can be used to ask any LLM (assuming it has a big enough context window) questions about the AI SDK based on the most up-to-date documentation.

### [Example Usage](#example-usage)

For instance, to prompt an LLM with questions about the AI SDK:

1. Copy the documentation contents from [ai-sdk.dev/llms.txt](/llms.txt)
2. Use the following prompt format:

```
Documentation:



{paste documentation here}



---



Based on the above documentation, answer the following:



{your question}
```

[Next

AI SDK 6 Beta](/docs/announcing-ai-sdk-6-beta)

On this page

[AI SDK](#ai-sdk)

[Why use the AI SDK?](#why-use-the-ai-sdk)

[Model Providers](#model-providers)

[Templates](#templates)

[Starter Kits](#starter-kits)

[Feature Exploration](#feature-exploration)

[Frameworks](#frameworks)

[Generative UI](#generative-ui)

[Security](#security)

[Join our Community](#join-our-community)

[llms.txt (for Cursor, Windsurf, Copilot, Claude etc.)](#llmstxt-for-cursor-windsurf-copilot-claude-etc)

[Example Usage](#example-usage)

Deploy and Scale AI Apps with Vercel

Deliver AI experiences globally with one push.

Trusted by industry leaders:

* OpenAI
* Photoroom
* ![leonardo-ai Logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-leonardo-ai-light.526e111b.svg&w=384&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)![leonardo-ai Logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-leonardo-ai-dark.8b6b14e3.svg&w=384&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)
* ![zapier Logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-zapier-light.7b452767.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)![zapier Logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-zapier-dark.bfd8e374.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)

[Sign Up](https://vercel.com/signup?utm_source=ai-sdk_site&utm_medium=docs_card&utm_content=sign-up)

#### Resources

[Docs](/docs)[Cookbook](/cookbook)[Providers](/providers)[Tools Registry](/tools-registry)[Showcase](/showcase)[GitHub](https://github.com/vercel/ai)[Discussions](https://github.com/vercel/ai/discussions)

#### More

[Playground](/playground)[Workflow Dev Kit](https://useworkflow.dev/)[Flags SDK](https://flags-sdk.dev/)[Contact Sales](https://vercel.com/contact/sales)

#### About Vercel

[Next.js + Vercel](https://vercel.com/frameworks/nextjs)[Open Source Software](https://vercel.com/oss)[GitHub](https://github.com/vercel)[X](https://x.com/vercel)

#### Legal

[Privacy Policy](https://vercel.com/legal/privacy-policy)

© 2025 Vercel, Inc.
</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
I can see there's an Agents section in the AI SDK documentation. Let me fetch the specific agents documentation to understand how to write an AI SDK agent.</details></think>

---

I see there's an Agents section. Let me fetch the specific documentation on building agents.

---

<tool-use data-tool-type="mcp" data-tool-name="mcp_vercel_fetch_docs">
<details>
          <summary>Tool use: **mcp_vercel_fetch_docs**</summary>
      
*Called tool*: vercel - fetch_docs: Fetch and parse documentation from a given URL or local file.

Use this tool after list_doc_sources to:
1. First fetch the llms.txt file from a documentation source
2. Analyze the URLs listed in the llms.txt file
3. Then fetch specific documentation pages relevant to the user's question

Args:
    url: The URL to fetch documentation from.

Returns:
    The fetched documentation content converted to markdown, or an error message
    if the request fails or the URL is not from an allowed domain.

*Parameters*:
  * url: https://ai-sdk.dev/docs/agents/overview

*Result*:
Agents: Agents

* [Docs](/docs)
* [Cookbook](/cookbook)
* [Providers](/providers)
* [Tools RegistryTools](/tools-registry)
* [Playground](/playground)
* [AI ElementsAI Elements](/elements)
* [AI GatewayGateway](https://vercel.com/ai-gateway)

AI SDK 6 is in Beta.

[Learn more](/docs/introduction/announcing-ai-sdk-6-beta)

Menu

v5 (Latest)

AI SDK 5.x

[AI SDK by Vercel](/docs/introduction)

[AI SDK 6 Beta](/docs/announcing-ai-sdk-6-beta)

[Foundations](/docs/foundations)

[Overview](/docs/foundations/overview)

[Providers and Models](/docs/foundations/providers-and-models)

[Prompts](/docs/foundations/prompts)

[Tools](/docs/foundations/tools)

[Streaming](/docs/foundations/streaming)

[Getting Started](/docs/getting-started)

[Navigating the Library](/docs/getting-started/navigating-the-library)

[Next.js App Router](/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](/docs/getting-started/nextjs-pages-router)

[Svelte](/docs/getting-started/svelte)

[Vue.js (Nuxt)](/docs/getting-started/nuxt)

[Node.js](/docs/getting-started/nodejs)

[Expo](/docs/getting-started/expo)

[Agents](/docs/agents)

[Agents](/docs/agents/overview)

[Building Agents](/docs/agents/building-agents)

[Workflow Patterns](/docs/agents/workflows)

[Loop Control](/docs/agents/loop-control)

[AI SDK Core](/docs/ai-sdk-core)

[Overview](/docs/ai-sdk-core/overview)

[Generating Text](/docs/ai-sdk-core/generating-text)

[Generating Structured Data](/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](/docs/ai-sdk-core/tools-and-tool-calling)

[Model Context Protocol (MCP)](/docs/ai-sdk-core/mcp-tools)

[Prompt Engineering](/docs/ai-sdk-core/prompt-engineering)

[Settings](/docs/ai-sdk-core/settings)

[Embeddings](/docs/ai-sdk-core/embeddings)

[Image Generation](/docs/ai-sdk-core/image-generation)

[Transcription](/docs/ai-sdk-core/transcription)

[Speech](/docs/ai-sdk-core/speech)

[Language Model Middleware](/docs/ai-sdk-core/middleware)

[Provider & Model Management](/docs/ai-sdk-core/provider-management)

[Error Handling](/docs/ai-sdk-core/error-handling)

[Testing](/docs/ai-sdk-core/testing)

[Telemetry](/docs/ai-sdk-core/telemetry)

[AI SDK UI](/docs/ai-sdk-ui)

[Overview](/docs/ai-sdk-ui/overview)

[Chatbot](/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Resume Streams](/docs/ai-sdk-ui/chatbot-resume-streams)

[Chatbot Tool Usage](/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](/docs/ai-sdk-ui/completion)

[Object Generation](/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](/docs/ai-sdk-ui/streaming-data)

[Error Handling](/docs/ai-sdk-ui/error-handling)

[Transport](/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](/docs/ai-sdk-rsc)

[Advanced](/docs/advanced)

[Reference](/docs/reference)

[AI SDK Core](/docs/reference/ai-sdk-core)

[AI SDK UI](/docs/reference/ai-sdk-ui)

[AI SDK RSC](/docs/reference/ai-sdk-rsc)

[Stream Helpers](/docs/reference/stream-helpers)

[AI SDK Errors](/docs/reference/ai-sdk-errors)

[Migration Guides](/docs/migration-guides)

[Troubleshooting](/docs/troubleshooting)

[Agents](/docs/agents)Overview

Copy markdown

[Agents](#agents)
=================

Agents are **large language models (LLMs)** that use **tools** in a **loop** to accomplish tasks.

These components work together:

* **LLMs** process input and decide the next action
* **Tools** extend capabilities beyond text generation (reading files, calling APIs, writing to databases)
* **Loop** orchestrates execution through:
  + **Context management** - Maintaining conversation history and deciding what the model sees (input) at each step
  + **Stopping conditions** - Determining when the loop (task) is complete

[Agent Class](#agent-class)
---------------------------

The Agent class handles these three components. Here's an agent that uses multiple tools in a loop to accomplish a task:

```
import { Experimental_Agent as Agent, stepCountIs, tool } from 'ai';



import { z } from 'zod';



const weatherAgent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



tools: {



weather: tool({



description: 'Get the weather in a location (in Fahrenheit)',



inputSchema: z.object({



location: z.string().describe('The location to get the weather for'),



}),



execute: async ({ location }) => ({



location,



temperature: 72 + Math.floor(Math.random() * 21) - 10,



}),



}),



convertFahrenheitToCelsius: tool({



description: 'Convert temperature from Fahrenheit to Celsius',



inputSchema: z.object({



temperature: z.number().describe('Temperature in Fahrenheit'),



}),



execute: async ({ temperature }) => {



const celsius = Math.round((temperature - 32) * (5 / 9));



return { celsius };



},



}),



},



stopWhen: stepCountIs(20),



});



const result = await weatherAgent.generate({



prompt: 'What is the weather in San Francisco in celsius?',



});



console.log(result.text); // agent's final answer



console.log(result.steps); // steps taken by the agent
```

The agent automatically:

1. Calls the `weather` tool to get the temperature in Fahrenheit
2. Calls `convertFahrenheitToCelsius` to convert it
3. Generates a final text response with the result

The Agent class handles the loop, context management, and stopping conditions.

[Why Use the Agent Class?](#why-use-the-agent-class)
----------------------------------------------------

The Agent class is the recommended approach for building agents with the AI SDK because it:

* **Reduces boilerplate** - Manages loops and message arrays
* **Improves reusability** - Define once, use throughout your application
* **Simplifies maintenance** - Single place to update agent configuration

For most use cases, start with the Agent class. Use core functions (`generateText`, `streamText`) when you need explicit control over each step for complex structured workflows.

[Structured Workflows](#structured-workflows)
---------------------------------------------

Agents are flexible and powerful, but non-deterministic. When you need reliable, repeatable outcomes with explicit control flow, use core functions with structured workflow patterns combining:

* Conditional statements for explicit branching
* Standard functions for reusable logic
* Error handling for robustness
* Explicit control flow for predictability

[Explore workflow patterns](/docs/agents/workflows) to learn more about building structured, reliable systems.

[Next Steps](#next-steps)
-------------------------

* **[Building Agents](/docs/agents/building-agents)** - Guide to creating agents with the Agent class
* **[Workflow Patterns](/docs/agents/workflows)** - Structured patterns using core functions for complex workflows
* **[Loop Control](/docs/agents/loop-control)** - Execution control with stopWhen and prepareStep

[Previous

Agents](/docs/agents)[Next

Building Agents](/docs/agents/building-agents)

On this page

[Agents](#agents)

[Agent Class](#agent-class)

[Why Use the Agent Class?](#why-use-the-agent-class)

[Structured Workflows](#structured-workflows)

[Next Steps](#next-steps)

Deploy and Scale AI Apps with Vercel

Deliver AI experiences globally with one push.

Trusted by industry leaders:

* OpenAI
* Photoroom
* ![leonardo-ai Logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-leonardo-ai-light.526e111b.svg&w=384&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)![leonardo-ai Logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-leonardo-ai-dark.8b6b14e3.svg&w=384&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)
* ![zapier Logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-zapier-light.7b452767.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)![zapier Logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-zapier-dark.bfd8e374.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)

[Sign Up](https://vercel.com/signup?utm_source=ai-sdk_site&utm_medium=docs_card&utm_content=sign-up)

#### Resources

[Docs](/docs)[Cookbook](/cookbook)[Providers](/providers)[Tools Registry](/tools-registry)[Showcase](/showcase)[GitHub](https://github.com/vercel/ai)[Discussions](https://github.com/vercel/ai/discussions)

#### More

[Playground](/playground)[Workflow Dev Kit](https://useworkflow.dev/)[Flags SDK](https://flags-sdk.dev/)[Contact Sales](https://vercel.com/contact/sales)

#### About Vercel

[Next.js + Vercel](https://vercel.com/frameworks/nextjs)[Open Source Software](https://vercel.com/oss)[GitHub](https://github.com/vercel)[X](https://x.com/vercel)

#### Legal

[Privacy Policy](https://vercel.com/legal/privacy-policy)

© 2025 Vercel, Inc.
</details>
</tool-use>

---

<tool-use data-tool-type="mcp" data-tool-name="mcp_vercel_fetch_docs">
<details>
          <summary>Tool use: **mcp_vercel_fetch_docs**</summary>
      
*Called tool*: vercel - fetch_docs: Fetch and parse documentation from a given URL or local file.

Use this tool after list_doc_sources to:
1. First fetch the llms.txt file from a documentation source
2. Analyze the URLs listed in the llms.txt file
3. Then fetch specific documentation pages relevant to the user's question

Args:
    url: The URL to fetch documentation from.

Returns:
    The fetched documentation content converted to markdown, or an error message
    if the request fails or the URL is not from an allowed domain.

*Parameters*:
  * url: https://ai-sdk.dev/docs/agents/building-agents

*Result*:
Agents: Building Agents

* [Docs](/docs)
* [Cookbook](/cookbook)
* [Providers](/providers)
* [Tools RegistryTools](/tools-registry)
* [Playground](/playground)
* [AI ElementsAI Elements](/elements)
* [AI GatewayGateway](https://vercel.com/ai-gateway)

AI SDK 6 is in Beta.

[Learn more](/docs/introduction/announcing-ai-sdk-6-beta)

Menu

v5 (Latest)

AI SDK 5.x

[AI SDK by Vercel](/docs/introduction)

[AI SDK 6 Beta](/docs/announcing-ai-sdk-6-beta)

[Foundations](/docs/foundations)

[Overview](/docs/foundations/overview)

[Providers and Models](/docs/foundations/providers-and-models)

[Prompts](/docs/foundations/prompts)

[Tools](/docs/foundations/tools)

[Streaming](/docs/foundations/streaming)

[Getting Started](/docs/getting-started)

[Navigating the Library](/docs/getting-started/navigating-the-library)

[Next.js App Router](/docs/getting-started/nextjs-app-router)

[Next.js Pages Router](/docs/getting-started/nextjs-pages-router)

[Svelte](/docs/getting-started/svelte)

[Vue.js (Nuxt)](/docs/getting-started/nuxt)

[Node.js](/docs/getting-started/nodejs)

[Expo](/docs/getting-started/expo)

[Agents](/docs/agents)

[Agents](/docs/agents/overview)

[Building Agents](/docs/agents/building-agents)

[Workflow Patterns](/docs/agents/workflows)

[Loop Control](/docs/agents/loop-control)

[AI SDK Core](/docs/ai-sdk-core)

[Overview](/docs/ai-sdk-core/overview)

[Generating Text](/docs/ai-sdk-core/generating-text)

[Generating Structured Data](/docs/ai-sdk-core/generating-structured-data)

[Tool Calling](/docs/ai-sdk-core/tools-and-tool-calling)

[Model Context Protocol (MCP)](/docs/ai-sdk-core/mcp-tools)

[Prompt Engineering](/docs/ai-sdk-core/prompt-engineering)

[Settings](/docs/ai-sdk-core/settings)

[Embeddings](/docs/ai-sdk-core/embeddings)

[Image Generation](/docs/ai-sdk-core/image-generation)

[Transcription](/docs/ai-sdk-core/transcription)

[Speech](/docs/ai-sdk-core/speech)

[Language Model Middleware](/docs/ai-sdk-core/middleware)

[Provider & Model Management](/docs/ai-sdk-core/provider-management)

[Error Handling](/docs/ai-sdk-core/error-handling)

[Testing](/docs/ai-sdk-core/testing)

[Telemetry](/docs/ai-sdk-core/telemetry)

[AI SDK UI](/docs/ai-sdk-ui)

[Overview](/docs/ai-sdk-ui/overview)

[Chatbot](/docs/ai-sdk-ui/chatbot)

[Chatbot Message Persistence](/docs/ai-sdk-ui/chatbot-message-persistence)

[Chatbot Resume Streams](/docs/ai-sdk-ui/chatbot-resume-streams)

[Chatbot Tool Usage](/docs/ai-sdk-ui/chatbot-tool-usage)

[Generative User Interfaces](/docs/ai-sdk-ui/generative-user-interfaces)

[Completion](/docs/ai-sdk-ui/completion)

[Object Generation](/docs/ai-sdk-ui/object-generation)

[Streaming Custom Data](/docs/ai-sdk-ui/streaming-data)

[Error Handling](/docs/ai-sdk-ui/error-handling)

[Transport](/docs/ai-sdk-ui/transport)

[Reading UIMessage Streams](/docs/ai-sdk-ui/reading-ui-message-streams)

[Message Metadata](/docs/ai-sdk-ui/message-metadata)

[Stream Protocols](/docs/ai-sdk-ui/stream-protocol)

[AI SDK RSC](/docs/ai-sdk-rsc)

[Advanced](/docs/advanced)

[Reference](/docs/reference)

[AI SDK Core](/docs/reference/ai-sdk-core)

[AI SDK UI](/docs/reference/ai-sdk-ui)

[AI SDK RSC](/docs/reference/ai-sdk-rsc)

[Stream Helpers](/docs/reference/stream-helpers)

[AI SDK Errors](/docs/reference/ai-sdk-errors)

[Migration Guides](/docs/migration-guides)

[Troubleshooting](/docs/troubleshooting)

[Agents](/docs/agents)Building Agents

Copy markdown

[Building Agents](#building-agents)
===================================

The Agent class provides a structured way to encapsulate LLM configuration, tools, and behavior into reusable components. It handles the agent loop for you, allowing the LLM to call tools multiple times in sequence to accomplish complex tasks. Define agents once and use them across your application.

[Why Use the Agent Class?](#why-use-the-agent-class)
----------------------------------------------------

When building AI applications, you often need to:

* **Reuse configurations** - Same model settings, tools, and prompts across different parts of your application
* **Maintain consistency** - Ensure the same behavior and capabilities throughout your codebase
* **Simplify API routes** - Reduce boilerplate in your endpoints
* **Type safety** - Get full TypeScript support for your agent's tools and outputs

The Agent class provides a single place to define your agent's behavior.

[Creating an Agent](#creating-an-agent)
---------------------------------------

Define an agent by instantiating the Agent class with your desired configuration:

```
import { Experimental_Agent as Agent } from 'ai';



const myAgent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



system: 'You are a helpful assistant.',



tools: {



// Your tools here



},



});
```

[Configuration Options](#configuration-options)
-----------------------------------------------

The Agent class accepts all the same settings as `generateText` and `streamText`. Configure:

### [Model and System Prompt](#model-and-system-prompt)

```
import { Experimental_Agent as Agent } from 'ai';



const agent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



system: 'You are an expert software engineer.',



});
```

### [Tools](#tools)

Provide tools that the agent can use to accomplish tasks:

```
import { Experimental_Agent as Agent, tool } from 'ai';



import { z } from 'zod';



const codeAgent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



tools: {



runCode: tool({



description: 'Execute Python code',



inputSchema: z.object({



code: z.string(),



}),



execute: async ({ code }) => {



// Execute code and return result



return { output: 'Code executed successfully' };



},



}),



},



});
```

### [Loop Control](#loop-control)

By default, agents run for a single step (`stopWhen: stepCountIs(1)`). In each step, the model either generates text or calls a tool. If it generates text, the agent completes. If it calls a tool, the AI SDK executes that tool.

To let agents call multiple tools in sequence, configure `stopWhen` to allow more steps. After each tool execution, the agent triggers a new generation where the model can call another tool or generate text:

```
import { Experimental_Agent as Agent, stepCountIs } from 'ai';



const agent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



stopWhen: stepCountIs(20), // Allow up to 20 steps



});
```

Each step represents one generation (which results in either text or a tool call). The loop continues until:

* The model generates text instead of calling a tool, or
* A stop condition is met

You can combine multiple conditions:

```
import { Experimental_Agent as Agent, stepCountIs } from 'ai';



const agent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



stopWhen: [



stepCountIs(20), // Maximum 20 steps



yourCustomCondition(), // Custom logic for when to stop



],



});
```

Learn more about [loop control and stop conditions](/docs/agents/loop-control).

### [Tool Choice](#tool-choice)

Control how the agent uses tools:

```
import { Experimental_Agent as Agent } from 'ai';



const agent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



tools: {



// your tools here



},



toolChoice: 'required', // Force tool use



// or toolChoice: 'none' to disable tools



// or toolChoice: 'auto' (default) to let the model decide



});
```

You can also force the use of a specific tool:

```
import { Experimental_Agent as Agent } from 'ai';



const agent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



tools: {



weather: weatherTool,



cityAttractions: attractionsTool,



},



toolChoice: {



type: 'tool',



toolName: 'weather', // Force the weather tool to be used



},



});
```

### [Structured Output](#structured-output)

Define structured output schemas:

```
import { Experimental_Agent as Agent, Output, stepCountIs } from 'ai';



import { z } from 'zod';



const analysisAgent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



experimental_output: Output.object({



schema: z.object({



sentiment: z.enum(['positive', 'neutral', 'negative']),



summary: z.string(),



keyPoints: z.array(z.string()),



}),



}),



stopWhen: stepCountIs(10),



});



const { experimental_output: output } = await analysisAgent.generate({



prompt: 'Analyze customer feedback from the last quarter',



});
```

[Define Agent Behavior with System Prompts](#define-agent-behavior-with-system-prompts)
---------------------------------------------------------------------------------------

System prompts define your agent's behavior, personality, and constraints. They set the context for all interactions and guide how the agent responds to user queries and uses tools.

### [Basic System Prompts](#basic-system-prompts)

Set the agent's role and expertise:

```
const agent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



system:



'You are an expert data analyst. You provide clear insights from complex data.',



});
```

### [Detailed Behavioral Instructions](#detailed-behavioral-instructions)

Provide specific guidelines for agent behavior:

```
const codeReviewAgent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



system: `You are a senior software engineer conducting code reviews.



Your approach:



- Focus on security vulnerabilities first



- Identify performance bottlenecks



- Suggest improvements for readability and maintainability



- Be constructive and educational in your feedback



- Always explain why something is an issue and how to fix it`,



});
```

### [Constrain Agent Behavior](#constrain-agent-behavior)

Set boundaries and ensure consistent behavior:

```
const customerSupportAgent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



system: `You are a customer support specialist for an e-commerce platform.



Rules:



- Never make promises about refunds without checking the policy



- Always be empathetic and professional



- If you don't know something, say so and offer to escalate



- Keep responses concise and actionable



- Never share internal company information`,



tools: {



checkOrderStatus,



lookupPolicy,



createTicket,



},



});
```

### [Tool Usage Instructions](#tool-usage-instructions)

Guide how the agent should use available tools:

```
const researchAgent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



system: `You are a research assistant with access to search and document tools.



When researching:



1. Always start with a broad search to understand the topic



2. Use document analysis for detailed information



3. Cross-reference multiple sources before drawing conclusions



4. Cite your sources when presenting information



5. If information conflicts, present both viewpoints`,



tools: {



webSearch,



analyzeDocument,



extractQuotes,



},



});
```

### [Format and Style Instructions](#format-and-style-instructions)

Control the output format and communication style:

```
const technicalWriterAgent = new Agent({



model: 'anthropic/claude-sonnet-4.5',



system: `You are a technical documentation writer.



Writing style:



- Use clear, simple language



- Avoid jargon unless necessary



- Structure information with headers and bullet points



- Include code examples where relevant



- Write in second person ("you" instead of "the user")



Always format responses in Markdown.`,



});
```

[Using an Agent](#using-an-agent)
---------------------------------

Once defined, you can use your agent in three ways:

### [Generate Text](#generate-text)

Use `generate()` for one-time text generation:

```
const result = await myAgent.generate({



prompt: 'What is the weather like?',



});



console.log(result.text);
```

### [Stream Text](#stream-text)

Use `stream()` for streaming responses:

```
const stream = myAgent.stream({



prompt: 'Tell me a story',



});



for await (const chunk of stream.textStream) {



console.log(chunk);



}
```

### [Respond to UI Messages](#respond-to-ui-messages)

Use `respond()` to create API responses for client applications:

```
// In your API route (e.g., app/api/chat/route.ts)



import { validateUIMessages } from 'ai';



export async function POST(request: Request) {



const { messages } = await request.json();



return myAgent.respond({



messages: await validateUIMessages({ messages }),



});



}
```

[End-to-end Type Safety](#end-to-end-type-safety)
-------------------------------------------------

You can infer types for your Agent's `UIMessage`s:

```
import {



Experimental_Agent as Agent,



Experimental_InferAgentUIMessage as InferAgentUIMessage,



} from 'ai';



const myAgent = new Agent({



// ... configuration



});



// Infer the UIMessage type for UI components or persistence



export type MyAgentUIMessage = InferAgentUIMessage<typeof myAgent>;
```

Use this type in your client components with `useChat`:

components/chat.tsx

```
'use client';



import { useChat } from '@ai-sdk/react';



import type { MyAgentUIMessage } from '@/agent/my-agent';



export function Chat() {



const { messages } = useChat<MyAgentUIMessage>();



// Full type safety for your messages and tools



}
```

[Next Steps](#next-steps)
-------------------------

Now that you understand building agents, you can:

* Explore [workflow patterns](/docs/agents/workflows) for structured patterns using core functions
* Learn about [loop control](/docs/agents/loop-control) for advanced execution control
* See [manual loop examples](/cookbook/node/manual-agent-loop) for custom workflow implementations

[Previous

Agents](/docs/agents/overview)[Next

Workflow Patterns](/docs/agents/workflows)

On this page

[Building Agents](#building-agents)

[Why Use the Agent Class?](#why-use-the-agent-class)

[Creating an Agent](#creating-an-agent)

[Configuration Options](#configuration-options)

[Model and System Prompt](#model-and-system-prompt)

[Tools](#tools)

[Loop Control](#loop-control)

[Tool Choice](#tool-choice)

[Structured Output](#structured-output)

[Define Agent Behavior with System Prompts](#define-agent-behavior-with-system-prompts)

[Basic System Prompts](#basic-system-prompts)

[Detailed Behavioral Instructions](#detailed-behavioral-instructions)

[Constrain Agent Behavior](#constrain-agent-behavior)

[Tool Usage Instructions](#tool-usage-instructions)

[Format and Style Instructions](#format-and-style-instructions)

[Using an Agent](#using-an-agent)

[Generate Text](#generate-text)

[Stream Text](#stream-text)

[Respond to UI Messages](#respond-to-ui-messages)

[End-to-end Type Safety](#end-to-end-type-safety)

[Next Steps](#next-steps)

Deploy and Scale AI Apps with Vercel

Deliver AI experiences globally with one push.

Trusted by industry leaders:

* OpenAI
* Photoroom
* ![leonardo-ai Logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-leonardo-ai-light.526e111b.svg&w=384&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)![leonardo-ai Logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-leonardo-ai-dark.8b6b14e3.svg&w=384&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)
* ![zapier Logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-zapier-light.7b452767.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)![zapier Logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-zapier-dark.bfd8e374.svg&w=256&q=75&dpl=dpl_3UQ4puuH1u2AFEjp5Hypi95TdmCC)

[Sign Up](https://vercel.com/signup?utm_source=ai-sdk_site&utm_medium=docs_card&utm_content=sign-up)

#### Resources

[Docs](/docs)[Cookbook](/cookbook)[Providers](/providers)[Tools Registry](/tools-registry)[Showcase](/showcase)[GitHub](https://github.com/vercel/ai)[Discussions](https://github.com/vercel/ai/discussions)

#### More

[Playground](/playground)[Workflow Dev Kit](https://useworkflow.dev/)[Flags SDK](https://flags-sdk.dev/)[Contact Sales](https://vercel.com/contact/sales)

#### About Vercel

[Next.js + Vercel](https://vercel.com/frameworks/nextjs)[Open Source Software](https://vercel.com/oss)[GitHub](https://github.com/vercel)[X](https://x.com/vercel)

#### Legal

[Privacy Policy](https://vercel.com/legal/privacy-policy)

© 2025 Vercel, Inc.
</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
I now have comprehensive information about how to write an AI SDK agent. Let me summarize this for the user.</details></think>

---

Based on the AI SDK documentation, here's how it tells you to write an agent:

## AI SDK Agent Pattern

The AI SDK uses an **`Agent` class** (currently experimental) that wraps an LLM with tools in an automatic loop. The key components are:

1. **LLM** - processes input and decides the next action
2. **Tools** - extend capabilities (file access, APIs, databases)
3. **Loop** - orchestrates execution with context management and stopping conditions

### Basic Agent Example

```typescript
import { Experimental_Agent as Agent, stepCountIs, tool } from 'ai';
import { z } from 'zod';

const weatherAgent = new Agent({
  model: 'anthropic/claude-sonnet-4.5',
  system: 'You are a helpful assistant.',
  tools: {
    weather: tool({
      description: 'Get the weather in a location (in Fahrenheit)',
      inputSchema: z.object({
        location: z.string().describe('The location to get the weather for'),
      }),
      execute: async ({ location }) => ({
        location,
        temperature: 72 + Math.floor(Math.random() * 21) - 10,
      }),
    }),
  },
  stopWhen: stepCountIs(20), // Allow up to 20 steps
});

// Usage
const result = await weatherAgent.generate({
  prompt: 'What is the weather in San Francisco?',
});
console.log(result.text);
```

### Key Configuration Options

| Option | Description |
|--------|-------------|
| `model` | The LLM to use (e.g., `'anthropic/claude-sonnet-4.5'`) |
| `system` | System prompt defining behavior/constraints |
| `tools` | Object of tools the agent can call |
| `stopWhen` | When to stop the loop (e.g., `stepCountIs(20)`) |
| `toolChoice` | `'auto'`, `'required'`, `'none'`, or specific tool |
| `experimental_output` | For structured output schemas |

### Three Ways to Use an Agent

1. **`generate()`** - one-time text generation
2. **`stream()`** - streaming responses
3. **`respond()`** - create API responses for client apps (useful for `useChat` hook)

```typescript
// Stream example
const stream = myAgent.stream({ prompt: 'Tell me a story' });
for await (const chunk of stream.textStream) {
  console.log(chunk);
}

// API route example
export async function POST(request: Request) {
  const { messages } = await request.json();
  return myAgent.respond({
    messages: await validateUIMessages({ messages }),
  });
}
```

**Note:** The Agent class is currently marked as `Experimental_Agent`, so the API may change in future versions.

---

